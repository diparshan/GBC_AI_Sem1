{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:3em;color:black;\"> Lab Exercise 6</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can download the original Kyphosis dataset from kaggle at https://www.kaggle.com/abbasit/kyphosis-dataset?select=kyphosis.csv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kyphosis_df = pd.read_csv('kyphosis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Kyphosis_df.drop('Kyphosis',axis=1)\n",
    "y = Kyphosis_df['Kyphosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nDecisionTreeClassifier(\\n    criterion='gini',\\n    splitter='best',\\n    max_depth=None,\\n    min_samples_split=2,\\n    min_samples_leaf=1,\\n    min_weight_fraction_leaf=0.0,\\n    max_features=None,\\n    random_state=None,\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    class_weight=None,\\n    presort=False,\\n)\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecting the right \"parameters/hyperparameters of ML models can significantly affect their performacnce\".\n",
    "# let's begin exploring those parameters more for a DT model.\n",
    "'''\n",
    "DecisionTreeClassifier(\n",
    "    criterion='gini',\n",
    "    splitter='best',\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    max_features=None,\n",
    "    random_state=None,\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    class_weight=None,\n",
    "    presort=False,\n",
    ")\n",
    "'''\n",
    "# Let's consider these three parameters: criterion, splitter, min_samples_split\n",
    "    # for parameters consider two cases 'gini' and 'entropy'\n",
    "    # for splitter consider two cases 'best' and 'random'\n",
    "    # for min_samples_split consider two cases 2 and 5\n",
    "    # explain and dicuss your findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  criterion splitter  min_samples_split  accuracy\n",
      "0      gini     best                  2      0.68\n",
      "1      gini     best                  5      0.64\n",
      "2      gini   random                  2      0.56\n",
      "3      gini   random                  5      0.56\n",
      "4   entropy     best                  2      0.64\n",
      "5   entropy     best                  5      0.56\n",
      "6   entropy   random                  2      0.64\n",
      "7   entropy   random                  5      0.60\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define hyperparameter combinations\n",
    "criteria = ['gini', 'entropy']\n",
    "splitters = ['best', 'random']\n",
    "min_samples = [2, 5]\n",
    "\n",
    "results = []\n",
    "\n",
    "for criterion in criteria:\n",
    "    for splitter in splitters:\n",
    "        for min_samples_split in min_samples:\n",
    "            # Create and train the model\n",
    "            model = DecisionTreeClassifier(\n",
    "                criterion=criterion,\n",
    "                splitter=splitter,\n",
    "                min_samples_split=min_samples_split,\n",
    "                random_state=42\n",
    "            )\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Make predictions\n",
    "            y_pred = model.predict(X_test)\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            results.append({\n",
    "                'criterion': criterion,\n",
    "                'splitter': splitter,\n",
    "                'min_samples_split': min_samples_split,\n",
    "                'accuracy': accuracy\n",
    "            })\n",
    "\n",
    "# Convert results to DataFrame for better analysis\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
